{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from lima_gui import Chat, ChatDataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Example dataset\n",
    "dataset = ChatDataset.from_csv('chatgpt_chats.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "6"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'name': 'Nucleus sampling', 'lang': 'en', 'dialog': [{'role': 'user', 'content': 'What is nucleus sampling in the context of LLMs'}, {'role': 'assistant', 'content': 'Nucleus sampling is a technique used in the context of large language models (LLMs), such as GPT-3, to generate more diverse and controlled text outputs. It is a method for improving the quality and variability of generated text by selecting from a subset of the most likely next words or tokens based on their probabilities.\\n\\nHere\\'s how nucleus sampling works:\\n\\n1. Token Probability Calculation: When generating text with an LLM, the model assigns probabilities to each possible next word or token in the sequence, based on the context and the language patterns it has learned during training.\\n\\n2. Determining the Nucleus: Instead of simply selecting the token with the highest probability (as in greedy sampling) or sampling from the entire probability distribution (as in temperature-based sampling), nucleus sampling focuses on a dynamic subset of the most probable tokens.\\n\\n3. Threshold Selection: A threshold probability (usually denoted as \"p\") is chosen. This threshold represents the cumulative probability mass of the most likely tokens. The threshold is selected based on the desired level of diversity in the generated text. For example, if you set p = 0.8, the model will consider the most probable tokens whose cumulative probability adds up to 80%.\\n\\n4. Token Selection: The model then samples from this subset of tokens whose cumulative probabilities exceed the chosen threshold \"p.\" This means that the actual number of tokens considered can vary depending on the threshold and the specific probability distribution at each step.\\n\\nNucleus sampling helps strike a balance between generating coherent text (by focusing on high-probability tokens) and introducing variability and creativity (by allowing for less probable but still relatively likely tokens). This makes the generated text more interesting and diverse while maintaining some level of control over the output.\\n\\nIn summary, nucleus sampling is a technique used in LLMs to improve the quality and diversity of generated text by dynamically selecting from a subset of the most likely next tokens based on a threshold probability, allowing for a controlled yet varied text generation process.'}], 'tags': ['conversational', 'world qa']}"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chat = dataset.get_chat(0)\n",
    "chat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Name Nucleus sampling\n",
      "Language: en\n",
      "Tags: ['conversational', 'world qa']\n",
      "\n",
      "\n",
      "///---///\n",
      "user\n",
      "---\n",
      "What is nucleus sampling in the context of LLMs\n",
      "\n",
      "///---///\n",
      "assistant\n",
      "---\n",
      "Nucleus sampling is a technique used in the context of large language models (LLMs), such as GPT-3, to generate more diverse and controlled text outputs. It is a method for improving the quality and variability of generated text by selecting from a subset of the most likely next words or tokens based on their probabilities.\n",
      "\n",
      "Here's how nucleus sampling works:\n",
      "\n",
      "1. Token Probability Calculation: When generating text with an LLM, the model assigns probabilities to each possible next word or token in the sequence, based on the context and the language patterns it has learned during training.\n",
      "\n",
      "2. Determining the Nucleus: Instead of simply selecting the token with the highest probability (as in greedy sampling) or sampling from the entire probability distribution (as in temperature-based sampling), nucleus sampling focuses on a dynamic subset of the most probable tokens.\n",
      "\n",
      "3. Threshold Selection: A threshold probability (usually denoted as \"p\") is chosen. This threshold represents the cumulative probability mass of the most likely tokens. The threshold is selected based on the desired level of diversity in the generated text. For example, if you set p = 0.8, the model will consider the most probable tokens whose cumulative probability adds up to 80%.\n",
      "\n",
      "4. Token Selection: The model then samples from this subset of tokens whose cumulative probabilities exceed the chosen threshold \"p.\" This means that the actual number of tokens considered can vary depending on the threshold and the specific probability distribution at each step.\n",
      "\n",
      "Nucleus sampling helps strike a balance between generating coherent text (by focusing on high-probability tokens) and introducing variability and creativity (by allowing for less probable but still relatively likely tokens). This makes the generated text more interesting and diverse while maintaining some level of control over the output.\n",
      "\n",
      "In summary, nucleus sampling is a technique used in LLMs to improve the quality and diversity of generated text by dynamically selecting from a subset of the most likely next tokens based on a threshold probability, allowing for a controlled yet varied text generation process.\n"
     ]
    }
   ],
   "source": [
    "print('Name', chat.name)\n",
    "print('Language:', chat.language)\n",
    "print('Tags:', chat.tags)\n",
    "print()\n",
    "\n",
    "for message in chat.chat['dialog']:\n",
    "    print('\\n///---///')\n",
    "    print(message['role'])\n",
    "    print('---')\n",
    "    print(message['content'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'name': 'Nucleus sampling',\n",
       "  'lang': 'en',\n",
       "  'dialog': [{'role': 'user',\n",
       "    'content': 'What is nucleus sampling in the context of LLMs'},\n",
       "   {'role': 'assistant',\n",
       "    'content': 'Nucleus sampling is a technique used in the context of large language models (LLMs), such as GPT-3, to generate more diverse and controlled text outputs. It is a method for improving the quality and variability of generated text by selecting from a subset of the most likely next words or tokens based on their probabilities.\\n\\nHere\\'s how nucleus sampling works:\\n\\n1. Token Probability Calculation: When generating text with an LLM, the model assigns probabilities to each possible next word or token in the sequence, based on the context and the language patterns it has learned during training.\\n\\n2. Determining the Nucleus: Instead of simply selecting the token with the highest probability (as in greedy sampling) or sampling from the entire probability distribution (as in temperature-based sampling), nucleus sampling focuses on a dynamic subset of the most probable tokens.\\n\\n3. Threshold Selection: A threshold probability (usually denoted as \"p\") is chosen. This threshold represents the cumulative probability mass of the most likely tokens. The threshold is selected based on the desired level of diversity in the generated text. For example, if you set p = 0.8, the model will consider the most probable tokens whose cumulative probability adds up to 80%.\\n\\n4. Token Selection: The model then samples from this subset of tokens whose cumulative probabilities exceed the chosen threshold \"p.\" This means that the actual number of tokens considered can vary depending on the threshold and the specific probability distribution at each step.\\n\\nNucleus sampling helps strike a balance between generating coherent text (by focusing on high-probability tokens) and introducing variability and creativity (by allowing for less probable but still relatively likely tokens). This makes the generated text more interesting and diverse while maintaining some level of control over the output.\\n\\nIn summary, nucleus sampling is a technique used in LLMs to improve the quality and diversity of generated text by dynamically selecting from a subset of the most likely next tokens based on a threshold probability, allowing for a controlled yet varied text generation process.'}],\n",
       "  'tags': ['conversational', 'world qa']},\n",
       " {'name': 'tf logging',\n",
       "  'lang': 'en',\n",
       "  'dialog': [{'role': 'user',\n",
       "    'content': 'How can I disable tensorflow logging?'},\n",
       "   {'role': 'assistant',\n",
       "    'content': \"To disable TensorFlow logging, you can adjust the logging verbosity level using TensorFlow's built-in functions. TensorFlow provides a logging mechanism that allows you to control the amount of information that is printed to the console or saved to log files. Here's how you can set the logging verbosity level to silence or limit the amount of logging information:\\n\\n1. **Silencing all TensorFlow logging:**\\n\\nTo completely silence all TensorFlow log messages, you can set the TensorFlow logging verbosity to only show critical messages. Add the following code to your script or Jupyter Notebook before importing TensorFlow:\\n\\n```python\\nimport os\\nos.environ['TF_CPP_MIN_LOG_LEVEL'] = '3'\\nimport tensorflow as tf\\n```\\n\\nThis code sets the environment variable `TF_CPP_MIN_LOG_LEVEL` to '3', which tells TensorFlow to only log critical messages.\\n\\n2. **Controlling TensorFlow logging verbosity:**\\n\\nIf you want more fine-grained control over the verbosity level, you can set the logging verbosity using TensorFlow's `tf.compat.v1.logging.set_verbosity` function. This allows you to choose one of the following verbosity levels: 'DEBUG', 'INFO', 'WARN', 'ERROR', or 'FATAL'. For example:\\n\\n```python\\nimport tensorflow as tf\\ntf.compat.v1.logging.set_verbosity(tf.compat.v1.logging.ERROR)\\n```\\n\\nThis code sets the logging verbosity to only show error and fatal messages. You can choose the verbosity level that best suits your needs.\\n\\nRemember that the method you choose may depend on your specific use case and whether you want to completely silence all TensorFlow logging or control the verbosity level. In most cases, setting `TF_CPP_MIN_LOG_LEVEL` to '3' or using `tf.compat.v1.logging.set_verbosity` with an appropriate level should suffice.\"},\n",
       "   {'role': 'user',\n",
       "    'content': '```\\nCould not load symbol cublasGetSmCountTarget from libcublas.so.11. Error: /usr/local/cuda/lib64/libcublas.so.11: undefined symbol: cublasGetSmCountTarget\\n```\\nDo you know what this error means?'},\n",
       "   {'role': 'assistant',\n",
       "    'content': \"The error message you're encountering suggests that there is an issue with loading the symbol `cublasGetSmCountTarget` from the CUDA library `libcublas.so.11`. This typically happens when there is a mismatch between the CUDA version and the cuBLAS library version, or there may be a problem with your CUDA installation.\\n\\nHere are some steps to diagnose and potentially resolve the issue:\\n\\n1. **Check CUDA Version:**\\nEnsure that you have the correct version of CUDA installed on your system that is compatible with the version of cuBLAS you are using. You can check your CUDA version using the following command:\\n\\n```\\nnvcc --version\\n```\\n\\nMake sure that the version matches what your TensorFlow or other GPU-dependent library expects.\\n\\n2. **Check cuBLAS Version:**\\nVerify that you have the appropriate version of cuBLAS installed. The error message suggests that you have cuBLAS version 11 installed. You should ensure that this version is compatible with your CUDA version.\\n\\n3. **Library Paths:**\\nCheck your library paths to ensure that the correct versions of CUDA and cuBLAS libraries are being loaded. You can use the `ldd` command to check the library dependencies of a specific library file. For example:\\n\\n```\\nldd /usr/local/cuda/lib64/libcublas.so.11\\n```\\n\\nThis will show you which shared libraries are being linked with `libcublas.so.11`.\\n\\n4. **Reinstall CUDA and cuBLAS:**\\nIf you suspect a version mismatch or corruption of CUDA or cuBLAS, consider reinstalling them from the official NVIDIA website or package manager.\\n\\n5. **Environment Variables:**\\nCheck your environment variables related to CUDA and cuBLAS. Make sure that `LD_LIBRARY_PATH` or `LD_PRELOAD` does not point to incompatible or incorrect library paths.\\n\\n6. **TensorFlow Version:**\\nIf you are using TensorFlow, ensure that you are using a TensorFlow version that is compatible with your CUDA and cuBLAS versions. Different TensorFlow versions have different compatibility requirements.\\n\\n7. **System Updates:**\\nEnsure that your system is up to date with the latest updates and patches for CUDA, cuBLAS, and the operating system itself.\\n\\n8. **Check GPU Driver:**\\nMake sure you have the appropriate GPU driver installed and that it is compatible with your CUDA and cuBLAS versions.\\n\\nBy following these steps, you should be able to diagnose and resolve the issue related to the `cublasGetSmCountTarget` symbol error. It's crucial to ensure that all the GPU-related libraries and dependencies are consistent and correctly configured for your environment.\"}],\n",
       "  'tags': ['conversational', 'world qa']},\n",
       " {'name': 'Pyqt contextual',\n",
       "  'lang': 'en',\n",
       "  'dialog': [{'role': 'user',\n",
       "    'content': 'How do I enable smooth scrolling in the ListWidget in PyQt6? My current widget scrolls through entire items instead of scrolling smoothly'},\n",
       "   {'role': 'assistant',\n",
       "    'content': 'In PyQt6, you can enable smooth scrolling in a `QListWidget` by adjusting its scrolling properties. By default, `QListWidget` uses the default scrolling behavior provided by the underlying operating system, which may not always be smooth. To achieve smooth scrolling, you can adjust the scroll bar properties and scroll step size. Here\\'s how you can do it:\\n\\n```python\\nimport sys\\nfrom PyQt6.QtCore import Qt\\nfrom PyQt6.QtWidgets import QApplication, QListWidget, QListWidgetItem, QVBoxLayout, QWidget\\n\\nclass SmoothScrollListWidget(QListWidget):\\n    def __init__(self):\\n        super().__init__()\\n        self.setVerticalScrollBarPolicy(Qt.ScrollBarPolicy.ScrollBarAlwaysOn)  # Show vertical scroll bar always\\n        self.setVerticalScrollMode(QListWidget.ScrollMode.ScrollPerPixel)  # Scroll pixel by pixel for smoother scrolling\\n\\n        # Adjust the scroll step size (optional)\\n        self.setVerticalScrollBar(self.verticalScrollBar())  # Get the vertical scroll bar\\n        self.verticalScrollBar().setSingleStep(10)  # Set a custom step size (adjust as needed)\\n\\n        # Add some items to the list for testing\\n        for i in range(100):\\n            item = QListWidgetItem(f\"Item {i}\")\\n            self.addItem(item)\\n\\nclass MainWindow(QWidget):\\n    def __init__(self):\\n        super().__init__()\\n        self.setWindowTitle(\"Smooth Scrolling Example\")\\n        self.setGeometry(100, 100, 400, 300)\\n\\n        layout = QVBoxLayout()\\n        smooth_scroll_list = SmoothScrollListWidget()\\n        layout.addWidget(smooth_scroll_list)\\n        self.setLayout(layout)\\n\\nif __name__ == \\'__main__\\':\\n    app = QApplication(sys.argv)\\n    main_window = MainWindow()\\n    main_window.show()\\n    sys.exit(app.exec())\\n```\\n\\nIn this code:\\n\\n1. We create a custom `SmoothScrollListWidget` class that inherits from `QListWidget`.\\n2. We set the vertical scroll bar to always be visible using `setVerticalScrollBarPolicy`.\\n3. We set the vertical scroll mode to `ScrollPerPixel` to enable smoother pixel-by-pixel scrolling.\\n4. Optionally, you can adjust the scroll step size using `setSingleStep` to control how much the list widget scrolls with each scroll event.\\n\\nBy customizing these properties, you can achieve smoother scrolling in your `QListWidget` in PyQt6. Adjust the step size and other properties as needed to fine-tune the scrolling behavior to your preferences.'},\n",
       "   {'role': 'user',\n",
       "    'content': \"Thanks, that's exactly what I needed.\\n\\nOne more question. I have implemented a chat window in PyQT. Here is it's general structure:\\n- QListWidget\\n  - ChatItem (A custom class that inherits QWidget).\\n    - TextEdit\\n\\nThe problem is that the TextEdit component does not stretch according to its contents. So if the message is big, I have to scroll inside the ChatItem to read all the text. How do I make it stretch so that all the text is visible at once? I don't want to scroll within individual ChatItems, I want them to show the whole text and scroll inside the chat window (QListWidget) if needed.\"},\n",
       "   {'role': 'assistant',\n",
       "    'content': 'To make the `TextEdit` component inside your `ChatItem` stretch according to its contents and show all the text without the need for internal scrolling within the `ChatItem`, you can use layout management. Specifically, you can use a `QVBoxLayout` to ensure that the `TextEdit` expands vertically to accommodate the text.\\n\\nHere\\'s how you can modify your `ChatItem` class to achieve this:\\n\\n```python\\nimport sys\\nfrom PyQt6.QtWidgets import QApplication, QListWidget, QListWidgetItem, QTextEdit, QVBoxLayout, QWidget\\n\\nclass ChatItem(QWidget):\\n    def __init__(self, text):\\n        super().__init__()\\n\\n        layout = QVBoxLayout()  # Create a vertical layout for the ChatItem\\n        text_edit = QTextEdit()  # Create a QTextEdit widget for the text\\n        text_edit.setPlainText(text)  # Set the text content\\n        text_edit.setReadOnly(True)  # Make the QTextEdit read-only\\n        layout.addWidget(text_edit)  # Add the QTextEdit to the layout\\n\\n        self.setLayout(layout)  # Set the layout for the ChatItem\\n\\nclass MainWindow(QWidget):\\n    def __init__(self):\\n        super().__init__()\\n        self.setWindowTitle(\"Chat Window Example\")\\n        self.setGeometry(100, 100, 400, 300)\\n\\n        list_widget = QListWidget()\\n        list_widget.setVerticalScrollBarPolicy(Qt.ScrollBarPolicy.ScrollBarAlwaysOn)\\n        list_widget.setVerticalScrollMode(QListWidget.ScrollMode.ScrollPerPixel)\\n\\n        # Add some chat items to the list for testing\\n        for i in range(10):\\n            text = f\"Lorem ipsum dolor sit amet, consectetur adipiscing elit. Item {i}\"\\n            item = QListWidgetItem()\\n            list_widget.addItem(item)\\n            list_widget.setItemWidget(item, ChatItem(text))\\n\\n        layout = QVBoxLayout()\\n        layout.addWidget(list_widget)\\n        self.setLayout(layout)\\n\\nif __name__ == \\'__main__\\':\\n    app = QApplication(sys.argv)\\n    main_window = MainWindow()\\n    main_window.show()\\n    sys.exit(app.exec())\\n```\\n\\nIn this code:\\n\\n1. We create a `ChatItem` class that inherits from `QWidget` and contains a `QTextEdit` widget.\\n2. Inside the `ChatItem` constructor, we create a `QVBoxLayout` and add a `QTextEdit` widget to it.\\n3. We set the `QTextEdit` widget to read-only mode so that the user cannot edit its content.\\n4. We set the layout of the `ChatItem` to the vertical layout we created.\\n5. In the `MainWindow`, we create a `QListWidget` and add `ChatItem` instances as items. The `QListWidgetItem` is associated with a `ChatItem` widget using `setItemWidget`.\\n\\nThis approach ensures that the `QTextEdit` in each `ChatItem` stretches to fit its content, and you can scroll through the chat window (the `QListWidget`) if needed.'},\n",
       "   {'role': 'user',\n",
       "    'content': 'Here some more context about my case: \\nThe ChatItem already uses QVBoxLayout. Here is the whole hierarchy of the ChatItem:\\n- QWidget\\n  - QVBoxLayot\\n    - TextEdit\\n    - QWidget\\n      - QHBoxLayout (here I contain some additional data about the chat item)\\n        - QComboBox\\n        - QLabel\\n\\nAlso the TextEdit is editable.'},\n",
       "   {'role': 'assistant',\n",
       "    'content': 'If the `TextEdit` is already inside a `QVBoxLayout` and you want it to stretch to fit its content while keeping it editable, you can achieve this by setting the `QTextEdit`\\'s `sizePolicy` to `Expanding` for both horizontal and vertical directions. Additionally, you may want to ensure that the `QVBoxLayout` containing the `TextEdit` has the `sizeConstraint` set to `SetMinimumSize` to allow it to expand vertically.\\n\\nHere\\'s how you can modify your `ChatItem` to achieve this:\\n\\n```python\\nimport sys\\nfrom PyQt6.QtCore import Qt\\nfrom PyQt6.QtWidgets import QApplication, QListWidget, QListWidgetItem, QTextEdit, QVBoxLayout, QWidget\\n\\nclass ChatItem(QWidget):\\n    def __init__(self, text):\\n        super().__init__()\\n\\n        layout = QVBoxLayout()  # Create a vertical layout for the ChatItem\\n        text_edit = QTextEdit()  # Create a QTextEdit widget for the text\\n        text_edit.setPlainText(text)  # Set the text content\\n        text_edit.setReadOnly(False)  # Make the QTextEdit editable\\n\\n        # Set the QTextEdit\\'s sizePolicy to Expanding\\n        text_edit.setSizePolicy(\\n            QtWidgets.QSizePolicy.Policy.Expanding,\\n            QtWidgets.QSizePolicy.Policy.Expanding\\n        )\\n\\n        layout.addWidget(text_edit)  # Add the QTextEdit to the layout\\n\\n        # Add any additional widgets to the QHBoxLayout if needed\\n        additional_data_widget = QWidget()\\n        additional_data_layout = QHBoxLayout()\\n        combo_box = QComboBox()\\n        label = QLabel(\"Additional Data\")\\n        additional_data_layout.addWidget(combo_box)\\n        additional_data_layout.addWidget(label)\\n        additional_data_widget.setLayout(additional_data_layout)\\n\\n        layout.addWidget(additional_data_widget)\\n\\n        # Ensure that the QVBoxLayout allows expanding vertically\\n        layout.setSizeConstraint(QLayout.SizeConstraint.SetMinimumSize)\\n\\n        self.setLayout(layout)  # Set the layout for the ChatItem\\n\\nclass MainWindow(QWidget):\\n    def __init__(self):\\n        super().__init__()\\n        self.setWindowTitle(\"Chat Window Example\")\\n        self.setGeometry(100, 100, 400, 300)\\n\\n        list_widget = QListWidget()\\n        list_widget.setVerticalScrollBarPolicy(Qt.ScrollBarPolicy.ScrollBarAlwaysOn)\\n        list_widget.setVerticalScrollMode(QListWidget.ScrollMode.ScrollPerPixel)\\n\\n        # Add some chat items to the list for testing\\n        for i in range(10):\\n            text = f\"Lorem ipsum dolor sit amet, consectetur adipiscing elit. Item {i}\"\\n            item = QListWidgetItem()\\n            list_widget.addItem(item)\\n            list_widget.setItemWidget(item, ChatItem(text))\\n\\n        layout = QVBoxLayout()\\n        layout.addWidget(list_widget)\\n        self.setLayout(layout)\\n\\nif __name__ == \\'__main__\\':\\n    app = QApplication(sys.argv)\\n    main_window = MainWindow()\\n    main_window.show()\\n    sys.exit(app.exec())\\n```\\n\\nWith these changes, the `TextEdit` widget will expand both horizontally and vertically to fit its content while remaining editable. The `QVBoxLayout` containing it will allow expanding vertically as well.'},\n",
       "   {'role': 'user',\n",
       "    'content': 'I made corresponding adjustments but it still does not expand. What else can I do?'},\n",
       "   {'role': 'assistant',\n",
       "    'content': \"If the `TextEdit` inside your `ChatItem` is not expanding as expected despite setting the size policy to `Expanding` for both horizontal and vertical directions, there may be other factors affecting its behavior. Here are some additional steps you can take to ensure proper expansion:\\n\\n1. **Check the Parent Layout**: Confirm that the parent layout (the `QVBoxLayout` in your case) allows expansion in the vertical direction. You can set the size constraint for the parent layout to `SetMinimumSize` to allow it to expand.\\n\\n```python\\nlayout.setSizeConstraint(QLayout.SizeConstraint.SetMinimumSize)\\n```\\n\\n2. **Ensure Minimum Size Constraints**: Ensure that the `QTextEdit` and other widgets inside the `ChatItem` don't have a fixed minimum size that prevents them from expanding. By default, widgets like `QTextEdit` have a minimum size constraint, and you may need to adjust it to allow expansion.\\n\\n```python\\ntext_edit.setMinimumSize(0, 0)  # Ensure there's no fixed minimum size\\n```\\n\\n3. **Check Parent Widget**: Make sure that the parent widget of the `ChatItem` (e.g., the `QListWidget`) is not constraining the size of its items. Ensure that the parent widget's size policy allows its children to expand.\\n\\n```python\\nlist_widget.setSizePolicy(\\n    QtWidgets.QSizePolicy.Policy.Expanding,\\n    QtWidgets.QSizePolicy.Policy.Expanding\\n)\\n```\\n\\n4. **Verify the Layout Update**: Ensure that the layout is being updated properly. After adding items to the `QListWidget`, you can call `adjustSize()` on the parent widget to trigger a layout update.\\n\\n```python\\nlist_widget.adjustSize()\\n```\\n\\n5. **Verify Other Styling and Constraints**: Check for any other styling or constraints that may be affecting the widget's size.\\n\\nIf, after checking these aspects, the `TextEdit` still doesn't expand as expected, it may be helpful to inspect your entire layout hierarchy and the CSS styling (if applicable) to identify any factors that could be limiting the widget's size.\\n\\nAdditionally, ensure that you're using the latest version of PyQt6, as some behavior may be influenced by specific versions of the library. If all else fails, you can consider using the `QScrollArea` widget to contain your `ChatItem` and allow for scrolling within individual items while keeping them compact.\"}],\n",
       "  'tags': ['conversational', 'coding']},\n",
       " {'name': 'clone branch',\n",
       "  'lang': 'en',\n",
       "  'dialog': [{'role': 'user',\n",
       "    'content': 'How do I clone a repo from a particular branch?'},\n",
       "   {'role': 'assistant',\n",
       "    'content': 'To clone a Git repository from a specific branch, you can use the `git clone` command with the `-b` flag followed by the branch name. Here\\'s the general syntax:\\n\\n```bash\\ngit clone -b branch_name repository_url\\n```\\n\\nReplace `branch_name` with the name of the branch you want to clone, and `repository_url` with the URL of the Git repository. Here\\'s a step-by-step guide:\\n\\n1. Open your terminal or command prompt.\\n\\n2. Navigate to the directory where you want to clone the repository if necessary. You can use the `cd` command to change directories.\\n\\n3. Use the `git clone` command with the `-b` flag and the branch name to clone the repository:\\n\\n```bash\\ngit clone -b branch_name repository_url\\n```\\n\\nFor example, if you want to clone a repository named \"myrepo\" from the branch \"development\" located on GitHub, the command would look like this:\\n\\n```bash\\ngit clone -b development https://github.com/yourusername/myrepo.git\\n```\\n\\nReplace \"yourusername\" with your GitHub username and adjust the repository URL accordingly.\\n\\nThis will clone the repository and checkout the specified branch so that you can start working on it.'}],\n",
       "  'tags': ['conversational', 'coding']},\n",
       " {'name': 'japanese texts',\n",
       "  'lang': 'en',\n",
       "  'dialog': [{'role': 'user',\n",
       "    'content': \"Give me japanese text to translate. I'm about n3 level in Japanese, take it into account\\nAlso provide vocab for words that could be unfamiliar for me\"},\n",
       "   {'role': 'assistant',\n",
       "    'content': \"Sure, here's a Japanese sentence for you to translate:\\n\\n原子力発電所は環境に影響を与える可能性がある。\\n\\nVocabulary:\\n1. 原子力発電所 (げんしりょくはつでんしょ) - Nuclear power plant\\n2. 環境 (かんきょう) - Environment\\n3. 影響 (えいきょう) - Influence, impact\\n4. 可能性 (かのうせい) - Possibility\\n\\nFeel free to translate the sentence, and if you have any questions or need further assistance, please let me know!\"},\n",
       "   {'role': 'user',\n",
       "    'content': \"There is a change that nuclear power plant affects it's environment.\\n\\nGive me a longer text, like 5 sentences. And harder.\"},\n",
       "   {'role': 'assistant',\n",
       "    'content': 'Certainly, here\\'s a more complex Japanese text for you to translate:\\n\\n日本の伝統文化は長い歴史を持ち、美しい工芸品や精巧な建築物を生み出してきました。伝統的な着物である着物は、特に日本の文化の象徴とされ、芸者や舞妓が身に着けることで知られています。茶道や華道などの芸道も、日本の伝統文化の一部であり、精神的な深さを持っています。また、古典文学作品である『源氏物語』は、日本文学の傑作として広く認識されています。これらの要素は日本文化の豊かさと多様性を示しており、世界中で愛されています。\\n\\nVocabulary:\\n1. 伝統文化 (でんとうぶんか) - Traditional culture\\n2. 美しい (うつくしい) - Beautiful\\n3. 工芸品 (こうげいひん) - Handicrafts\\n4. 着物 (きもの) - Kimono\\n5. 文化の象徴 (ぶんかのしょうちょう) - Symbol of culture\\n6. 芸者 (げいしゃ) - Geisha\\n7. 舞妓 (まいこ) - Maiko (apprentice geisha)\\n8. 芸道 (げいどう) - Traditional arts\\n9. 精神的な深さ (せいしんてきなふかさ) - Spiritual depth\\n10. 古典文学作品 (こてんぶんがくさくひん) - Classic literary work\\n11. 『源氏物語』 (げんじものがたり) - \"The Tale of Genji\"\\n\\nPlease translate the text, and if you have any questions or need assistance with specific phrases or words, feel free to ask!'}],\n",
       "  'tags': ['conversational', 'creative text generation']},\n",
       " {'name': 'jp word explanation',\n",
       "  'lang': 'en',\n",
       "  'dialog': [{'role': 'user',\n",
       "    'content': 'What 悪びれる means? Can you provide sentences using it for in context examples?'},\n",
       "   {'role': 'assistant',\n",
       "    'content': 'The word \"悪びれる\" (Warubireru) is a Japanese term that can be translated to English as \"to feel ashamed\" or \"to be remorseful.\" It is used to describe a feeling of guilt, regret, or embarrassment about one\\'s actions or behavior. Here are some sentences using 悪びれる in context:\\n\\n1. 彼は自分の失敗に悪びれて、謝罪の手紙を書いた。\\n   (Kare wa jibun no shippai ni warubirete, shazai no tegami o kaita.)\\n   He felt ashamed of his mistake and wrote an apology letter.\\n\\n2. 彼女は人を傷つけてしまったことを悪びれている。\\n   (Kanojo wa hito o kizutsukete shimatta koto o warubirete iru.)\\n   She feels remorseful for having hurt someone.\\n\\n3. 私はその言葉を言ってしまって、後で悪びれました。\\n   (Watashi wa sono kotoba o itte shimatte, ato de warubiremashita.)\\n   I said those words and later felt embarrassed about it.\\n\\n4. 彼は自分の過ちを悪びれず、他人を責める傾向がある。\\n   (Kare wa jibun no ayamachi o warubirezu, tanin o semeru keikou ga aru.)\\n   He has a tendency to blame others and not feel remorseful for his mistakes.\\n\\n5. 彼はその行動が社会的に受け入れられないことを知り、悪びれるべきだと感じた。\\n   (Kare wa sono koudou ga shakaiteki ni ukeirerarenai koto o shiri, warubureru beki da to kanjita.)\\n   He realized that his actions were socially unacceptable and felt he should be ashamed.\\n\\nIn these sentences, 悪びれる is used to convey a sense of regret, shame, or remorse for something that has been done or said.'},\n",
       "   {'role': 'user', 'content': 'What about 勝算?'},\n",
       "   {'role': 'assistant',\n",
       "    'content': 'The word \"勝算\" (shousan) is a Japanese term that can be translated to English as \"chance of winning,\" \"probability of success,\" or \"winning prospect.\" It is often used in discussions related to competitions, games, or situations where there is an element of winning or losing. Here are some sentences using 勝算 in context:\\n\\n1. 彼の勝算は非常に高い。彼はほぼ確実に勝つだろう。\\n   (Kare no shousan wa hijou ni takai. Kare wa hobo kakujitsu ni katsu darou.)\\n   His chances of winning are very high. He will almost certainly win.\\n\\n2. この試合での勝算はどれくらいだろうか？\\n   (Kono shiai de no shousan wa dore kurai darou ka?)\\n   What\\'s the probability of success in this match?\\n\\n3. 彼女は競争に臨む前に、勝算を計算しました。\\n   (Kanojo wa kyousou ni nozomu mae ni, shousan o keisan shimashita.)\\n   She calculated her chances of success before entering the competition.\\n\\n4. 彼は勝算が低いことを知っていたが、最後まで諦めなかった。\\n   (Kare wa shousan ga hikui koto o shitte ita ga, saigo made akiramenakatta.)\\n   He knew he had a low chance of winning, but he didn\\'t give up until the end.\\n\\n5. チームの勝算は今回の試合でかなり高まった。\\n   (Chiimu no shousan wa konkai no shiai de kanari takamatta.)\\n   The team\\'s chances of winning significantly improved in this match.\\n\\nIn these sentences, 勝算 is used to discuss the likelihood or probability of achieving success, especially in competitive situations. It\\'s a term often used in sports, games, and various other contexts where outcomes are uncertain, and people want to assess their chances.'},\n",
       "   {'role': 'user', 'content': 'What about ほど遠い?'},\n",
       "   {'role': 'assistant',\n",
       "    'content': 'The phrase \"ほど遠い\" (hodo tooi) in Japanese can be translated to English as \"far from\" or \"far from being.\" It is used to convey that something is distant or remote in a figurative sense, typically indicating that an expectation, goal, or condition is far from being met. Here are some sentences using \"ほど遠い\" in context:\\n\\n1. 彼の能力はプロのレベルとはほど遠い。\\n   (Kare no nouryoku wa puro no reberu to wa hodo tooi.)\\n   His abilities are far from being at a professional level.\\n\\n2. 彼女の夢は現実のものとはほど遠いものだった。\\n   (Kanojo no yume wa genjitsu no mono to wa hodo tooi mono datta.)\\n   Her dream was far from being a reality.\\n\\n3. 彼の提案は実現可能性においてほど遠いと言わざるを得ない。\\n   (Kare no teian wa jitsugen kanousei ni oite hodo tooi to iwazaru o enai.)\\n   It\\'s hard not to say that his proposal is far from being feasible.\\n\\n4. その会社の成功は今のところほど遠い。\\n   (Sono kaisha no seikou wa ima no tokoro hodo tooi.)\\n   The company\\'s success is far from being achieved at the moment.\\n\\n5. 彼の行動は誠実さからほど遠いものだった。\\n   (Kare no koudou wa seijitsusa kara hodo tooi mono datta.)\\n   His actions were far from being sincere.\\n\\nIn these sentences, \"ほど遠い\" is used to emphasize the gap or difference between the current state or expectation and the desired or ideal state. It indicates that there is a significant distance or disparity between the two.'},\n",
       "   {'role': 'user', 'content': 'What about 在留?'},\n",
       "   {'role': 'assistant',\n",
       "    'content': 'The term \"在留\" (zairyu) is a Japanese word that can be translated to English as \"residence\" or \"residency.\" It is commonly used in the context of immigration and legal residency status in Japan. \"在留\" refers to the permission or status of residing in Japan for a specified period, whether for work, study, or other purposes. Here are some examples of how \"在留\" is used in context:\\n\\n1. 彼は日本での在留資格を取得するために必要な書類を提出しました。\\n   (Kare wa Nihon de no zairyu shikaku o shutoku suru tame ni hitsuyou na shorui o teishutsu shimashita.)\\n   He submitted the required documents to obtain a residence status in Japan.\\n\\n2. 外国人留学生は学生ビザを取得して、日本での在留を許可されます。\\n   (Gaikokujin ryuugakusei wa gakusei biza o shutoku shite, Nihon de no zairyu o kyoka saremasu.)\\n   Foreign students are granted permission for residence in Japan by obtaining a student visa.\\n\\n3. 長期間の在留が必要な場合は、更新手続きを行う必要があります。\\n   (Choukikan no zairyu ga hitsuyou na baai wa, koushin tetsuzuki o okonau hitsuyou ga arimasu.)\\n   If you need an extended period of residence, you must go through the renewal process.\\n\\n4. 在留資格に関する情報は、出入国管理局のウェブサイトで入手できます。\\n   (Zairyu shikaku ni kansuru jouhou wa, Nyuukokukanrikyoku no webusaito de nyuushu dekimasu.)\\n   Information about residence status can be obtained on the website of the Immigration Bureau.\\n\\n5. 結婚後、彼女は夫の在留資格を取得するために手続きを始めました。\\n   (Kekkon-go, kanojo wa otto no zairyu shikaku o shutoku suru tame ni tetsuzuki o hajimemashita.)\\n   After getting married, she began the process to obtain her husband\\'s residence status.\\n\\nIn these sentences, \"在留\" is used to refer to legal residency or permission to reside in Japan, often related to visas and immigration procedures. It is a term frequently encountered when discussing immigration and living arrangements in Japan.'},\n",
       "   {'role': 'user', 'content': 'What about 負けじ?'},\n",
       "   {'role': 'assistant',\n",
       "    'content': 'The phrase \"負けじ\" (makeji) is a Japanese term that can be roughly translated to \"never give up,\" \"don\\'t lose heart,\" or \"refuse to be defeated.\" It\\'s a motivational expression used to encourage perseverance, determination, and a fighting spirit in the face of challenges or adversity. Here are some examples of how \"負けじ\" is used in context:\\n\\n1. 彼は試合で負けたけれど、負けじと練習を続けています。\\n   (Kare wa shiai de maketakereba, makeji to renshuu o tsuzuketeimasu.)\\n   He lost the match, but he continues to practice with a never-give-up attitude.\\n\\n2. 人生には困難な時期があるけれど、負けじと前進しなければなりません。\\n   (Jinsei ni wa konnan na jiki ga aru keredo, makeji to zenshin shinakereba narimasen.)\\n   Life has its challenging times, but you must keep moving forward with determination.\\n\\n3. このプロジェクトは難しい局面に立ち向かっていますが、チームは負けじと取り組んでいます。\\n   (Kono purojekuto wa muzukashii kyokumen ni tachimukatteimasu ga, chiimu wa makeji to torikundeimasu.)\\n   This project is facing difficult circumstances, but the team is tackling them with a never-give-up spirit.\\n\\n4. 人々は災害の後も、負けじと復興に取り組んでいます。\\n   (Hitobito wa saigai no ato mo, makeji to fukkou ni torikundeimasu.)\\n   Even after disasters, people continue to work on recovery with determination.\\n\\n5. 負けじ精神を持つことは成功への第一歩です。\\n   (Makeji seishin o motsu koto wa seikou e no daiippou desu.)\\n   Having a never-give-up attitude is the first step toward success.\\n\\n\"負けじ\" is a motivational expression that is often used in various contexts to inspire resilience and a positive outlook when facing obstacles or setbacks. It encourages individuals to keep pushing forward and not let defeat discourage them.'}],\n",
       "  'tags': ['conversational', 'creative text generation']}]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# If you need to access raw data\n",
    "# The underlying data format is just a list of dictionaries\n",
    "dataset.chats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'name': 'Nucleus sampling',\n",
       " 'lang': 'en',\n",
       " 'dialog': [{'role': 'user',\n",
       "   'content': 'What is nucleus sampling in the context of LLMs'},\n",
       "  {'role': 'assistant',\n",
       "   'content': 'Nucleus sampling is a technique used in the context of large language models (LLMs), such as GPT-3, to generate more diverse and controlled text outputs. It is a method for improving the quality and variability of generated text by selecting from a subset of the most likely next words or tokens based on their probabilities.\\n\\nHere\\'s how nucleus sampling works:\\n\\n1. Token Probability Calculation: When generating text with an LLM, the model assigns probabilities to each possible next word or token in the sequence, based on the context and the language patterns it has learned during training.\\n\\n2. Determining the Nucleus: Instead of simply selecting the token with the highest probability (as in greedy sampling) or sampling from the entire probability distribution (as in temperature-based sampling), nucleus sampling focuses on a dynamic subset of the most probable tokens.\\n\\n3. Threshold Selection: A threshold probability (usually denoted as \"p\") is chosen. This threshold represents the cumulative probability mass of the most likely tokens. The threshold is selected based on the desired level of diversity in the generated text. For example, if you set p = 0.8, the model will consider the most probable tokens whose cumulative probability adds up to 80%.\\n\\n4. Token Selection: The model then samples from this subset of tokens whose cumulative probabilities exceed the chosen threshold \"p.\" This means that the actual number of tokens considered can vary depending on the threshold and the specific probability distribution at each step.\\n\\nNucleus sampling helps strike a balance between generating coherent text (by focusing on high-probability tokens) and introducing variability and creativity (by allowing for less probable but still relatively likely tokens). This makes the generated text more interesting and diverse while maintaining some level of control over the output.\\n\\nIn summary, nucleus sampling is a technique used in LLMs to improve the quality and diversity of generated text by dynamically selecting from a subset of the most likely next tokens based on a threshold probability, allowing for a controlled yet varied text generation process.'}],\n",
       " 'tags': ['conversational', 'world qa']}"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chat.chat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "dev310",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
